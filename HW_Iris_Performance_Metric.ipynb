{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1ba710e",
   "metadata": {},
   "source": [
    "# This Code depicts how to evaluate the Performance Metrics of the Iris Dataset - Rubab Karim\n",
    "\n",
    "Iris: 150 samples, 4 features, 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d40072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a734e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "def euclidean_distance(v1, v2):\n",
    "    return np.sqrt(np.sum(     (v1 - v2) ** 2    ))\n",
    "\n",
    "def predict(test_x):\n",
    "    \n",
    "    ## calculate distances between test_x and all data samples in X\n",
    "    distances = [ euclidean_distance(test_x, x )  for x in X_train   ]\n",
    "    \n",
    "    ## distances is a vector of 30 distances \n",
    "    ## distances [23, 2,  145, 23  , 5,   17 , 890, ....]  =>>  []\n",
    "               \n",
    "    \n",
    "    ## sort by distance and return the k closest neighbors\n",
    "    ## argsort returns the indices of the k nearest neighbors\n",
    "    k_neighbor_indeces =   np.argsort(   distances   )[:k]\n",
    "    \n",
    "    ## extract labels from y_train\n",
    "    labels = [    y_train[i]  for i in k_neighbor_indeces   ]\n",
    "    ## imagine labels = [1, 1, 1, 0, 1]\n",
    "    \n",
    "\n",
    "    ##select the most common label in labels\n",
    "    most_common_label = Counter(labels).most_common(1)\n",
    "\n",
    "    return most_common_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39dafb2",
   "metadata": {},
   "source": [
    "### We then load the raw data for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b986731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset: Iris 150 samples, 4 features, 3 classes\n",
    "\n",
    "df = pd.read_csv('data/iris.data.csv', header=None)\n",
    "\n",
    "X = df.loc[1:, :3].values\n",
    "X = X.astype(float)\n",
    "\n",
    "y = df.loc[1:,  4 ].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(   y   )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d8d7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3               4\n",
      "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
      "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
      "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
      "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
      "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
      "..   ...  ...  ...  ...             ...\n",
      "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
      "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
      "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
      "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
      "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4b5eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "[1 2 2 1 2 1 2 1 0 2 1 0 0 0 1 2 0 0 0 1 0 1 2 0 1 2 0 1 2 1 1 2 1 0 2 2 1\n",
      " 0 1 1 0 2 0 0 1 1 1 2 2 1 0 0 2 2 0 0 0 1 2 0 2 2 0 1 1 2 1 2 0 2 1 2 1 1\n",
      " 1 0 1 1 0 1 2 2 0 1 2 2 0 2 0 1 2 2 2 2 1 1 2 2 0 1 2 0 1 2]\n",
      "[[5.8 2.7 3.9 1.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [6.  3.  4.8 1.8]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [6.3 2.9 5.6 1.8]]\n",
      "[[6.4 2.9 4.3 1.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.8 3.4 1.6 0.2]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42 )\n",
    "\n",
    "print(y_test)\n",
    "print(y_train)\n",
    "print(  X_train   )\n",
    "print(  X_test    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e8be76",
   "metadata": {},
   "source": [
    "### Defining the functions for Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e854cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_test):\n",
    "    accuracy_value = np.sum(y_pred == y_test) / len(y_test)\n",
    "    return accuracy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f308ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats_percentage_train_test(algorithm_name, y_test, y_pred):    \n",
    "     print(\"------------------------------------------------------\")\n",
    "     print(\"------------------------------------------------------\")\n",
    "    \n",
    "     print(\"algorithm is: \", algorithm_name)\n",
    "        \n",
    "     print('Accuracy: %.2f' % accuracy_score(y_test,   y_pred) )\n",
    "     \n",
    "     confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "     print(\"confusion matrix\")\n",
    "     print(confmat)\n",
    "     print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "     print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "     print('F1-measure: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f4961c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 2, 1, 2, 0, 1, 2, 1, 2, 2, 0, 0, 0, 0, 1, 2, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0]\n",
      "true labels below\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "list_of_pred_labels = []\n",
    "\n",
    "for test_x in X_test:\n",
    "    temp_pred = predict(test_x)   \n",
    "    list_of_pred_labels.append(   temp_pred[0][0]  )\n",
    "    \n",
    "print(list_of_pred_labels)\n",
    "print(\"true labels below\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d880caee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 2 0 1 2 1 2 2 0 0 0 0 1 2 2 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "true labels below\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(    list_of_pred_labels    )\n",
    "\n",
    "print(y_pred)\n",
    "print(\"true labels below\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a638c49",
   "metadata": {},
   "source": [
    "### Here, we define the Regression Models that are going to be used in this analysis.\n",
    "a) Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1577f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_linear():\n",
    "    return nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e70f0",
   "metadata": {},
   "source": [
    "### b) Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64dd355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_nn_1hidden():\n",
    "    \n",
    "    seq_model = nn.Sequential(\n",
    "        nn.Linear(1599, 599),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(599, 1),\n",
    "    \n",
    "    )\n",
    "    \n",
    "   # optimizer = optim.SGD(\n",
    "   #    model_fn_nn_1hidden.parameters(),\n",
    "   #    lr=1e-3  )\n",
    "    \n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa3014f",
   "metadata": {},
   "source": [
    "### c) Deep Neural Network with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ce71f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deep_learning_2hidden():\n",
    "    seq_model = nn.Sequential(\n",
    "        nn.Linear(1599, 1099),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(1099, 599),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(599, 1)\n",
    "    )\n",
    "    \n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6af3a",
   "metadata": {},
   "source": [
    "### d) Deep Neural Network with 4 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e2a66bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deep_learning_4hidden():\n",
    "    seq_model = nn.Sequential(\n",
    "        nn.Linear(1599, 1099),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(1099, 599),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(599, 199),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(199, 99),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(99, 1)\n",
    "    )\n",
    "    \n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f215427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "algorithm is:  model_fn_nn_1hidden\n",
      "Accuracy: 0.91\n",
      "confusion matrix\n",
      "[[19  0  0]\n",
      " [ 0 10  3]\n",
      " [ 0  1 12]]\n",
      "Precision: 0.916\n",
      "Recall: 0.911\n",
      "F1-measure: 0.911\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "res = print_stats_percentage_train_test('model_fn_nn_1hidden', y_test, y_pred)      #knn\n",
    "\n",
    "print(    res   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074c9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITS5200",
   "language": "python",
   "name": "its5200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
