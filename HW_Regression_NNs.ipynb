{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab17584",
   "metadata": {},
   "source": [
    "## This HW depicts various models for training the provided Dataset - Rubab Karim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437fd07b",
   "metadata": {},
   "source": [
    "### Importing the Winequaity-red Dataset in order to conduct an analysis of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c97d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2e06d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1599, 11])\n",
      "torch.Size([1599])\n"
     ]
    }
   ],
   "source": [
    "wine_path = 'data/winequality-red.csv'\n",
    "wineq_np = np.loadtxt(wine_path, dtype = np.float32, delimiter = ';', skiprows = 1)\n",
    "\n",
    "t_c = torch.from_numpy(  wineq_np  )\n",
    "\n",
    "# Reading the 'data/winequality-white.csv' file\n",
    "white = pd.read_csv(\"data/winequality-white.csv\", sep=';')\n",
    "\n",
    "X = t_c[:, :-1]\n",
    "Y = t_c[:, -1]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f536a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1599, 1])\n",
      "torch.Size([1599, 1, 11])\n"
     ]
    }
   ],
   "source": [
    "#t_c = torch.tensor(  t_c   )\n",
    "#t_u = torch.tensor(  t_u   )\n",
    "\n",
    "#print(t_u.shape)\n",
    "#print(t_c.shape)\n",
    "\n",
    "t_c = X.unsqueeze(1)\n",
    "t_u = Y.unsqueeze(1)\n",
    "\n",
    "print(t_u.shape)\n",
    "print(t_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9244360e",
   "metadata": {},
   "source": [
    "## After pre-processing, we split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0cc98d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a748b798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_val = int(0.3 * n_samples)\n",
    "n_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca193462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1426, 1337,  835,  ...,  662, 1482, 1190])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_indeces = torch.randperm(n_samples)\n",
    "shuffled_indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b007878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1426, 1337,  835,  ...,  954, 1579,  633])\n",
      "tensor([ 622,  435,  140, 1047,   54,  209,  877, 1336,  654,  249, 1351,  287,\n",
      "         198,  639, 1455,  953,  220, 1201, 1222,  250,  706,  432, 1037, 1407,\n",
      "         826,  987, 1462, 1478,  945,  807,  787,  171,  939,  828,  789,  570,\n",
      "         231,  195, 1306,  381, 1178, 1437,  601,   31,  676,  749, 1292,  352,\n",
      "         424, 1598,  124,  150,  439,  137,  331,  273, 1551,  373, 1473,  929,\n",
      "         357,   62,  821,  522,  537, 1464,  793,    1,  515,  715,  818, 1305,\n",
      "        1074, 1529, 1516,  516, 1435,    8, 1113,  368,   72, 1349,  782,  261,\n",
      "         131,  745,   92,  251,  702, 1122, 1191,   20,  858, 1032,  318,  634,\n",
      "         510,  247,   41,   33, 1031,  224,  491,  390, 1133, 1246, 1229,  724,\n",
      "         660,  478,  699,  178,  182, 1406,  983,  378,  327, 1027, 1483,  320,\n",
      "         372,  890,  964, 1249, 1302, 1180, 1069, 1514,  384, 1228,  813,  513,\n",
      "         736,   55,  705, 1509,  901,  791,  722,  341,  860, 1311,  475, 1540,\n",
      "         289,  974,  428, 1044,  994, 1361, 1152,  101, 1184,  820, 1097, 1244,\n",
      "         823, 1004,  977, 1022,  166,  767,  727,  109, 1527,  103, 1312,  386,\n",
      "         996, 1271, 1221, 1048,  575, 1025,  232,  589,  281, 1242, 1555,  155,\n",
      "         260,  241,  681,  690, 1499, 1098, 1140,  333, 1376,  805, 1107,  306,\n",
      "         282,   97,  985,  189,  677, 1410,  864,  637, 1371, 1086, 1436,   80,\n",
      "         566,   65, 1077,  217,  586,  635, 1300, 1203,  966,  349, 1438,  190,\n",
      "         886,  407,  863, 1461,  714, 1534, 1493,  872,  569,  215, 1278,  728,\n",
      "          64,  952,  602, 1566, 1569,  165,  179, 1155,  776,   44, 1417, 1259,\n",
      "         397,  701, 1492, 1067,  963,   47,  358,  303,  121,   30, 1139, 1153,\n",
      "         542,  154,  822, 1545,  726,  871, 1380,  523,  299,  503,  278,  403,\n",
      "        1071,  404, 1557, 1317,  157, 1062,  243,  961,  550,   26,  421,  133,\n",
      "        1597,  396,  317,  878,   86,  526,  173,   95, 1023,  110,   49,  678,\n",
      "         415, 1142,  176, 1394,  857, 1384, 1525,  582, 1245,  649,  461, 1353,\n",
      "         143, 1215,  709,  455,   69, 1171, 1466,  454, 1584,  643,   34, 1399,\n",
      "         308,  115,  780, 1072,  185, 1560,  393,  498, 1428,  298,  297, 1486,\n",
      "         193,  852,  917,  466, 1583,  119,  825,  755, 1364,  839,  638, 1024,\n",
      "        1118,  829,  645, 1589,  884, 1256,  226,  346,  867, 1521,  237,   32,\n",
      "        1277,  562,  630,  288,   71,  796,   46,  271, 1467,  291,  321, 1225,\n",
      "         849,  880,  354, 1330, 1329,  487, 1232,  808, 1500,  792, 1126,  688,\n",
      "         392, 1528,  870, 1083,  684, 1568, 1323,  844,   25, 1296,  202,  338,\n",
      "         941, 1273,  631,   14, 1488, 1352,  629, 1251,  481, 1127,  141,  147,\n",
      "        1061,  514,  938,  682,  988,  686, 1331,  205,  425, 1298,  669, 1340,\n",
      "         683, 1039, 1293,  831, 1284,  401,  360,  636, 1230,  413, 1045,  926,\n",
      "         668,  885,  995,  934, 1343,  801,  640,  862,  769,  221,  970,  923,\n",
      "         174, 1524,  615,  430,  986,  364,  790, 1357, 1505,  512,  583, 1444,\n",
      "         766, 1513, 1166,  293,  598,  483,  146, 1160,  697, 1297,  211,  100,\n",
      "         571,  444,  418,  765, 1187,  344,  363,   60, 1367,  865, 1375, 1185,\n",
      "        1260,  207,   48,  380,  419,  656, 1520,  768,  662, 1482, 1190])\n"
     ]
    }
   ],
   "source": [
    "train_indeces = shuffled_indeces[:-n_val]\n",
    "val_indeces = shuffled_indeces[-n_val:]\n",
    "\n",
    "print(train_indeces)\n",
    "print(val_indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81beb16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_u = t_u[train_indeces]\n",
    "train_t_c = t_c[train_indeces]\n",
    "\n",
    "val_t_u = t_u[val_indeces]\n",
    "val_t_c = t_c[val_indeces]\n",
    "\n",
    "train_t_u = 0.1 * train_t_u\n",
    "val_t_u   = 0.1 * val_t_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c8374",
   "metadata": {},
   "source": [
    "## After prepping the dataset, we now push it into the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0410bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_t_u, val_t_u, train_t_c, val_t_c):\n",
    "    \n",
    "    for epoch in range(1, n_epochs):\n",
    "        \n",
    "        train_t_p = model(train_t_u)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        val_t_p = model(val_t_u)\n",
    "        val_loss = loss_fn(val_t_p, val_t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Train Loss: \", train_loss.item())\n",
    "            print(\"Val Loss: \", val_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f7101",
   "metadata": {},
   "source": [
    "### Here, we define the Regression Models that are going to be used in this analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b68c1",
   "metadata": {},
   "source": [
    "#### a) Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "847c34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_linear():\n",
    "    return nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82313a7e",
   "metadata": {},
   "source": [
    "#### b) Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc740453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_nn_1hidden():\n",
    "    \n",
    "    seq_model = nn.Sequential(\n",
    "        nn.Linear(1, 11),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(11, 1),\n",
    "    \n",
    "    )\n",
    "    \n",
    "   # optimizer = optim.SGD(\n",
    "   #    model_fn_nn_1hidden.parameters(),\n",
    "   #    lr=1e-3  )\n",
    "    \n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de7a62",
   "metadata": {},
   "source": [
    "#### c) Deep Neural Network with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "549b6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deep_learning_2hidden():\n",
    "    seq_model = nn.Sequential(\n",
    "        nn.Linear(1, 15),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(15, 5),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(5, 1)\n",
    "    )\n",
    "    \n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183ed76",
   "metadata": {},
   "source": [
    "#### d) Deep Neural Network with 4 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "123cad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deep_learning_4hidden():\n",
    "    seq_model = nn.Sequential(\n",
    "        nn.Linear(1, 20),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(20, 15),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(15, 10),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(10, 5),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(5, 1)\n",
    "    )\n",
    "    \n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079f882d",
   "metadata": {},
   "source": [
    "### Now, we call the function loop and push data into the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92b8a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model_fn_linear()\n",
    "\n",
    "model = model_fn_nn_1hidden()\n",
    "\n",
    "#model = model_deep_learning_2hidden()\n",
    "\n",
    "#model = model_deep_learning_4hidden()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "loss_fn = nn.MSELoss().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973b6148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1120, 1, 11])) that is different to the input size (torch.Size([1120, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([479, 1, 11])) that is different to the input size (torch.Size([479, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  334.5809631347656\n",
      "Val Loss:  359.63262939453125\n",
      "Train Loss:  329.7444152832031\n",
      "Val Loss:  354.7177734375\n",
      "Train Loss:  324.2481384277344\n",
      "Val Loss:  349.1172790527344\n",
      "Train Loss:  318.1285705566406\n",
      "Val Loss:  342.8774108886719\n",
      "Train Loss:  311.40130615234375\n",
      "Val Loss:  336.0080261230469\n",
      "Train Loss:  304.3565979003906\n",
      "Val Loss:  328.80023193359375\n",
      "Train Loss:  297.43206787109375\n",
      "Val Loss:  321.6960754394531\n",
      "Train Loss:  291.06982421875\n",
      "Val Loss:  315.144287109375\n",
      "Train Loss:  285.6182556152344\n",
      "Val Loss:  309.5010070800781\n",
      "Train Loss:  281.27691650390625\n",
      "Val Loss:  304.9740295410156\n",
      "Train Loss:  278.0794677734375\n",
      "Val Loss:  301.60467529296875\n",
      "Train Loss:  275.9128723144531\n",
      "Val Loss:  299.2863464355469\n",
      "Train Loss:  274.56817626953125\n",
      "Val Loss:  297.8143615722656\n",
      "Train Loss:  273.8055725097656\n",
      "Val Loss:  296.9502868652344\n",
      "Train Loss:  273.4100036621094\n",
      "Val Loss:  296.4781188964844\n",
      "Train Loss:  273.2217102050781\n",
      "Val Loss:  296.23468017578125\n",
      "Train Loss:  273.13885498046875\n",
      "Val Loss:  296.1139221191406\n",
      "Train Loss:  273.1048278808594\n",
      "Val Loss:  296.05499267578125\n",
      "Train Loss:  273.091552734375\n",
      "Val Loss:  296.02587890625\n"
     ]
    }
   ],
   "source": [
    "result = training_loop(\n",
    "    \n",
    "    n_epochs = 1000,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_t_u = train_t_u,\n",
    "    val_t_u = val_t_u,\n",
    "    train_t_c = train_t_c,\n",
    "    val_t_c = val_t_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ddda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd6e9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd4f1eda",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITS5200",
   "language": "python",
   "name": "its5200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
