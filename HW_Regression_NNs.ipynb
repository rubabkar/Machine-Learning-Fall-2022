{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab17584",
   "metadata": {},
   "source": [
    "## This HW depicts various models for training the provided Dataset - Rubab Karim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437fd07b",
   "metadata": {},
   "source": [
    "### Importing the Winequaity-red Dataset in order to conduct an analysis of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4c97d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a2e06d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 4)\n",
      "(1599,)\n"
     ]
    }
   ],
   "source": [
    "#wine_path = 'data/winequality-red.csv'\n",
    "#wineq_np = np.loadtxt(wine_path, dtype = np.float32, delimiter = ';', skiprows = 0)\n",
    "\n",
    "wineq = pd.read_csv('data/winequality-red.csv', header = None, skiprows = 0)\n",
    "# wineq_np = \n",
    "\n",
    "# t_c = torch.from_numpy(  wineq_np  )\n",
    "\n",
    "# Reading the 'data/winequality-white.csv' file\n",
    "# white = pd.read_csv(\"data/winequality-white.csv\", sep=';')\n",
    "\n",
    "# X = t_c[:, :-1]\n",
    "# Y = t_c[:, -1]\n",
    "\n",
    "X = wineq.loc[1:, :3].values\n",
    "X = X.astype(float)\n",
    "\n",
    "\n",
    "y = wineq.loc[1:,  4 ].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(   y   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f536a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1599, 1])\n",
      "torch.Size([1599, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# X = torch.tensor(  X   )\n",
    "# Y= torch.tensor(  y   )\n",
    "\n",
    "# print(t_u.shape)\n",
    "# print(t_c.shape)\n",
    "\n",
    "t_c = X.unsqueeze(1)\n",
    "t_u = Y.unsqueeze(1)\n",
    "\n",
    "print(t_u.shape)\n",
    "print(t_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9244360e",
   "metadata": {},
   "source": [
    "## After pre-processing, we split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0cc98d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a748b798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_val = int(0.3 * n_samples)\n",
    "n_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca193462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 704, 1160,  391,  ...,  443, 1345, 1190])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_indeces = torch.randperm(n_samples)\n",
    "shuffled_indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b007878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 704, 1160,  391,  ...,  621, 1454,  329])\n",
      "tensor([1084,  191, 1001, 1290, 1373,  737, 1173, 1241, 1346, 1333,  416, 1006,\n",
      "         612,  214, 1093,  176,  888,  477, 1033, 1050,  163,  545,  415,  945,\n",
      "        1030,   65,  961,  619,  440,  753,  483,  114,  422,  573,  351, 1368,\n",
      "          94, 1066, 1166,  921,    1,  883,  554, 1415,  267, 1551,  495,  782,\n",
      "        1500,   89,   79,  112,  825,  219, 1498, 1165,  514, 1007,  632,  205,\n",
      "         424, 1014, 1387,    0, 1420,  236, 1239,  131,  878, 1163,  983,  284,\n",
      "         542,  858,  360,  994, 1269, 1353,  462,  723,  279,  591, 1242, 1307,\n",
      "        1582,  529, 1300, 1565,  299,  563, 1528, 1480,  204,  770,  696,  868,\n",
      "         130, 1288,  693,  788,  605, 1240,  775, 1383, 1370, 1265,  394,  785,\n",
      "         640, 1470,  192, 1453,  610, 1216, 1275, 1276,  269,  446,  100, 1475,\n",
      "        1123, 1057,  103,  347,   80,  801, 1095,   98,  643,  173,  874,  496,\n",
      "        1594,  540,  187, 1581,  372,  988,  199,  381,  584,  533, 1249,  887,\n",
      "        1252, 1535, 1432,  144,  969, 1018,  261, 1430,  570, 1592,  857,  324,\n",
      "         238,  692, 1088, 1506,  437, 1277,  386,  854, 1280,  910,  936, 1360,\n",
      "         248,  574, 1427, 1174,   71, 1132,  133, 1289,  946,  353,  318, 1588,\n",
      "        1376, 1473,  113, 1325, 1327, 1583,  377,  923, 1398,  848,  845, 1205,\n",
      "         552,  432,  431,   84, 1091, 1111, 1305,  524,   18, 1115,  827,  291,\n",
      "        1576, 1540,  235, 1587,  918,  743,  596, 1186,  393,  211, 1055,  736,\n",
      "        1580, 1279, 1525,  189,    6, 1294,  986,  561, 1034,  853,  200, 1090,\n",
      "         340,  966, 1270, 1532, 1566,  598, 1198, 1187,   17,  507, 1148,  421,\n",
      "         826,  126, 1425, 1127, 1063, 1367,  739,  680,  903,  867,  863,  835,\n",
      "         162,  930, 1244,  725,  438, 1441,  954, 1308,  667, 1098,  180,  962,\n",
      "         321, 1523,  856,  997,   43, 1212, 1237,  220, 1153, 1126,  942,  344,\n",
      "        1195, 1038, 1229, 1460,  254,  664,  916, 1020,  973, 1134,  676,  300,\n",
      "         120,  705, 1257,  475, 1180, 1214,  581,  171, 1516,  332,  474,  314,\n",
      "        1054,  815,  564,   57,  802,  400,  957,  494,  635,  273, 1169,  193,\n",
      "         485,  223, 1340,  258,   38,  566,  379, 1521,  148,  266, 1140,  654,\n",
      "         998, 1142, 1478,  759,  515,  984,   76, 1520, 1248, 1323,  750,  602,\n",
      "        1125,  642, 1117,  656,  806,   20, 1194, 1593,  633,  427,  149, 1231,\n",
      "        1431,  336, 1579,  257, 1380, 1009,   16, 1188, 1446,  587,  356,  905,\n",
      "          46,  368, 1351, 1149,  557,  790, 1315,  754, 1542,  262, 1268,   24,\n",
      "        1036, 1512,  908,  197, 1350,  390,  593,  459,  613,  603, 1233, 1285,\n",
      "         309, 1058,  900, 1426,  295,  275,  927,  707,  380,  688, 1356,  539,\n",
      "         807, 1045,  672,  843, 1574,  486,   83,  578, 1507,  411,  981,  898,\n",
      "         242, 1089, 1103, 1060, 1503, 1027,  301, 1359,  805,  228, 1177,  109,\n",
      "        1529,  251,  631, 1047, 1101, 1295,  895,  949,  433,   69,  914,  823,\n",
      "         877,  195, 1204, 1401,  409,  820, 1330,  755,  345, 1246,  547, 1074,\n",
      "          15, 1318,  292,  154,  457, 1474,   93,  830,  202,  107, 1320,   35,\n",
      "         418,  338, 1381, 1064, 1419,  136,   86,  536,  687, 1543, 1561, 1555,\n",
      "         906,  912,  221, 1152, 1254,  992, 1263, 1402,  443, 1345, 1190])\n"
     ]
    }
   ],
   "source": [
    "train_indeces = shuffled_indeces[:-n_val]\n",
    "val_indeces = shuffled_indeces[-n_val:]\n",
    "\n",
    "print(train_indeces)\n",
    "print(val_indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81beb16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_u = t_u[train_indeces]\n",
    "train_t_c = t_c[train_indeces]\n",
    "\n",
    "val_t_u = t_u[val_indeces]\n",
    "val_t_c = t_c[val_indeces]\n",
    "\n",
    "train_t_u = 0.1 * train_t_u\n",
    "val_t_u   = 0.1 * val_t_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c8374",
   "metadata": {},
   "source": [
    "## After prepping the dataset, we now push it into the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0410bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_t_u, val_t_u, train_t_c, val_t_c):\n",
    "    \n",
    "    for epoch in range(1, n_epochs):\n",
    "        \n",
    "        train_t_p = model(train_t_u)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        val_t_p = model(val_t_u)\n",
    "        val_loss = loss_fn(val_t_p, val_t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Train Loss: \", train_loss.item())\n",
    "            print(\"Val Loss: \", val_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f7101",
   "metadata": {},
   "source": [
    "### Here, we define the Regression Models that are going to be used in this analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b68c1",
   "metadata": {},
   "source": [
    "#### a) Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "847c34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_linear():\n",
    "    return nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82313a7e",
   "metadata": {},
   "source": [
    "#### b) Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc740453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_nn_1hidden():\n",
    "    \n",
    "    seq_model = nn.Sequential(\n",
    "        nn.Linear(1599, 599),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(599, 1),\n",
    "    \n",
    "    )\n",
    "    \n",
    "   # optimizer = optim.SGD(\n",
    "   #    model_fn_nn_1hidden.parameters(),\n",
    "   #    lr=1e-3  )\n",
    "    \n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de7a62",
   "metadata": {},
   "source": [
    "#### c) Deep Neural Network with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "549b6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deep_learning_2hidden():\n",
    "    seq_model = nn.Sequential(\n",
    "        nn.Linear(1599, 1099),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(1099, 599),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(599, 1)\n",
    "    )\n",
    "    \n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183ed76",
   "metadata": {},
   "source": [
    "#### d) Deep Neural Network with 4 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "123cad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deep_learning_4hidden():\n",
    "    seq_model = nn.Sequential(\n",
    "        nn.Linear(1599, 1099),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(1099, 599),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(599, 199),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(199, 99),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Linear(99, 1)\n",
    "    )\n",
    "    \n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079f882d",
   "metadata": {},
   "source": [
    "### Now, we call the function loop and push data into the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92b8a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model_fn_linear()\n",
    "\n",
    "model = model_fn_nn_1hidden()\n",
    "\n",
    "#model = model_deep_learning_2hidden()\n",
    "\n",
    "#model = model_deep_learning_4hidden()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "loss_fn = nn.MSELoss().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "973b6148",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1120x1 and 1599x599)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_t_u\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_t_u\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_t_u\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_t_u\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_t_c\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_t_c\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_t_c\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_t_c\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, loss_fn, train_t_u, val_t_u, train_t_c, val_t_c)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_loop\u001b[39m(n_epochs, optimizer, model, loss_fn, train_t_u, val_t_u, train_t_c, val_t_c):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs):\n\u001b[0;32m----> 5\u001b[0m         train_t_p \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_t_u\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m loss_fn(train_t_p, train_t_c)\n\u001b[1;32m      8\u001b[0m         val_t_p \u001b[38;5;241m=\u001b[39m model(val_t_u)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1120x1 and 1599x599)"
     ]
    }
   ],
   "source": [
    "result = training_loop(\n",
    "    \n",
    "    n_epochs = 1000,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_t_u = train_t_u,\n",
    "    val_t_u = val_t_u,\n",
    "    train_t_c = train_t_c,\n",
    "    val_t_c = val_t_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ddda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd6e9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd4f1eda",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITS5200",
   "language": "python",
   "name": "its5200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
