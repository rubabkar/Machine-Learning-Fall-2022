{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd38735",
   "metadata": {},
   "source": [
    "# ITS5200 - Applied Machine Learning Final Project by \n",
    "\n",
    "#### Rubabul Karim (karim12@pnw.edu), \n",
    "#### Rusaful Karim (karim11@pnw.edu), \n",
    "#### Wahaj (mwahajud@pnw.edu), \n",
    "#### Mohammed Al Hamad (hamad@pnw.edu), \n",
    "\n",
    "### To - Prof. Ricardo Calix, Ph.D (rcalix@pnw.edu)\n",
    "\n",
    "\n",
    "This project is an elaborate demonstration of how the accuracy of datasets can be manipulated by attacking it with morphed data from the dataset and training the dataset with these 'adversarial images'. This report will include the following:\n",
    "\n",
    "b) A ML baseline for image classification.\n",
    "\n",
    "c) The Performance Metrics of both before and after the adversarial attack has been done.\n",
    "\n",
    "d) A demonstration of adding adversarial images to the training process to try and manipulate the end result. \n",
    "\n",
    "e) A conclusive display of how many adversarial images (Target: 5%) are needed to lower performance significantly.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87453b7a",
   "metadata": {},
   "source": [
    "### We start by downloading the core libraries for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1fdda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import time\n",
    "import tqdm\n",
    "import copy\n",
    "import requests, io\n",
    "from PIL import Image\n",
    "from icecream import ic\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, r2_score, accuracy_score, mean_absolute_error, mean_squared_error, mean_squared_error, recall_score, precision_score\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9aa56c",
   "metadata": {},
   "source": [
    "### For this Project, we are using the STL10 Dataset\n",
    "\n",
    "The STL-10 dataset is an image recognition dataset for developing unsupervised feature learning, deep learning, self-taught learning algorithms. It is inspired by the CIFAR-10 dataset but with some modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d784d150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.STL10(root='./data', split = 'train', transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.STL10(root='./data', split = 'test', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2873a50d",
   "metadata": {},
   "source": [
    "### After loading the dataset, we set the parameters that will be used for Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e980a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_OF_EPOCHS = 20\n",
    "LEARNING_RATE = 0.01\n",
    "DECAY = 0.00000 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e1823",
   "metadata": {},
   "source": [
    "### We can then load the data using DataLoader using the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abcc7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a44a34",
   "metadata": {},
   "source": [
    "### Using the ResNet 50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333ade4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m num_ftrs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_ftrs, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/nn/modules/module.py:307\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/nn/modules/module.py:203\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 203\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    207\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    208\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    214\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/nn/modules/module.py:225\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 225\u001b[0m         param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/nn/modules/module.py:307\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/cuda/__init__.py:149\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use CUDA with multiprocessing, you must use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg)\n\u001b[0;32m--> 149\u001b[0m \u001b[43m_check_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/cuda/__init__.py:47\u001b[0m, in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_driver\u001b[39m():\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_isDriverSufficient\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_isDriverSufficient():\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDriverVersion() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;66;03m# found no NVIDIA driver on the system\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True) \n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc584e4",
   "metadata": {},
   "source": [
    "### Setting the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9d33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548927be",
   "metadata": {},
   "source": [
    "### Training the Model before the Adversarial attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47906890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, net, criterion, optimizer):\n",
    "    net.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_samples = 0.0\n",
    "    running_correct = 0.0\n",
    "\n",
    "    for epoch in range(1, NUM_OF_EPOCHS+1):\n",
    "        ic('Epoch: ', epoch)\n",
    "        for data in loader:\n",
    "            img, label = data\n",
    "\n",
    "            running_samples += img.size(0)\n",
    "\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            output_score = net(img) \n",
    "            loss = criterion(output_score, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            _, pred = torch.max(output_score, 1)\n",
    "            num_correct = (pred == label).sum().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_correct += num_correct\n",
    "\n",
    "        average_loss = running_loss / running_samples\n",
    "        average_accuracy = running_correct / running_samples\n",
    "\n",
    "        ic('Training loss: {:.4f}, Acc: {:.4f} '.format(average_loss, average_accuracy,))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7cedb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| 'Epoch: ', epoch: 1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loader, net, criterion, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m img, label \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     13\u001b[0m running_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     17\u001b[0m output_score \u001b[38;5;241m=\u001b[39m net(img) \n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/cuda/__init__.py:149\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use CUDA with multiprocessing, you must use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg)\n\u001b[0;32m--> 149\u001b[0m \u001b[43m_check_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/cuda/__init__.py:47\u001b[0m, in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_driver\u001b[39m():\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_isDriverSufficient\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_isDriverSufficient():\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDriverVersion() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;66;03m# found no NVIDIA driver on the system\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "train(train_loader, model, criterion=loss, optimizer=opt) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07baf91c",
   "metadata": {},
   "source": [
    "### Performance Metrics for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ea077b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m y_true \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m----> 5\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \n\u001b[1;32m      7\u001b[0m         output \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mexp(output), \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      8\u001b[0m         y_pred\u001b[38;5;241m.\u001b[39mextend(output) \n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/cuda/__init__.py:149\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use CUDA with multiprocessing, you must use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg)\n\u001b[0;32m--> 149\u001b[0m \u001b[43m_check_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/cuda/__init__.py:47\u001b[0m, in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_driver\u001b[39m():\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_isDriverSufficient\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_isDriverSufficient():\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDriverVersion() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;66;03m# found no NVIDIA driver on the system\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "        output = model(inputs.cuda()) \n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) \n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) \n",
    "\n",
    "classes = ('airplane', 'bird', 'car', 'cat', 'deer',\n",
    "        'dog', 'horse', 'monkey', 'ship', 'truck')\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "\n",
    "plt.figure(figsize = (12,7))\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "\n",
    "avg = 'micro'\n",
    "ic(f'ACCURACY OF THE MODEL: {accuracy_score(y_true, y_pred)}')\n",
    "ic(f'PRECISION OF MODEL: {precision_score(y_true, y_pred, average=avg)}')\n",
    "ic(f'RECALL OF MODEL: {recall_score(y_true, y_pred, average=avg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7fd9ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(input,epsilon,data_grad):\n",
    "\n",
    "  pert_out = input + epsilon*data_grad.sign()\n",
    "  pert_out = torch.clamp(pert_out, 0, 1)\n",
    "  return pert_out\n",
    "\n",
    "def ifgsm_attack(input,epsilon,data_grad):\n",
    "\n",
    "  iter = 10\n",
    "  alpha = epsilon/iter\n",
    "  pert_out = input\n",
    "  for i in range(iter-1):\n",
    "    pert_out = pert_out + alpha*data_grad.sign()\n",
    "    pert_out = torch.clamp(pert_out, 0, 1)\n",
    "    if torch.norm((pert_out-input),p=float('inf')) > epsilon:\n",
    "      break\n",
    "  return pert_out\n",
    "\n",
    "def mifgsm_attack(input,epsilon,data_grad):\n",
    "\n",
    "  iter=10\n",
    "  decay_factor=1.0\n",
    "  pert_out = input\n",
    "  alpha = epsilon/iter\n",
    "  g=0\n",
    "\n",
    "  for i in range(iter-1):\n",
    "      \n",
    "    g = decay_factor*g + data_grad/torch.norm(data_grad,p=1)\n",
    "    pert_out = pert_out + alpha*torch.sign(g)\n",
    "    pert_out = torch.clamp(pert_out, 0, 1)\n",
    "\n",
    "    if torch.norm((pert_out-input),p=float('inf')) > epsilon:\n",
    "      break\n",
    "\n",
    "  return pert_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75b4381",
   "metadata": {},
   "source": [
    "### Using Adversarial Images to evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f3ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,device,test_loader,epsilon,attack):\n",
    "\n",
    "  correct = 0\n",
    "  adv_examples = []\n",
    "  model.eval()\n",
    "\n",
    "  for img, label in test_loader:\n",
    "      img, label = img.to(device), label.to(device)\n",
    "      img.requires_grad = True\n",
    "      output = model(img)\n",
    "\n",
    "      init_pred = output.max(1, keepdim=True)[1] \n",
    "\n",
    "      if init_pred.item != label.item:\n",
    "          continue\n",
    "\n",
    "      loss = loss(output, label)\n",
    "      model.zero_grad()\n",
    "      loss.backward()\n",
    "      data_grad = img.grad.data\n",
    "\n",
    "      if attack == \"fgsm\":\n",
    "        perturbed_data = fgsm_attack(img,epsilon,data_grad)\n",
    "      elif attack == \"ifgsm\":\n",
    "        perturbed_data = ifgsm_attack(img,epsilon,data_grad)\n",
    "      elif attack == \"mifgsm\":\n",
    "        perturbed_data = mifgsm_attack(img,epsilon,data_grad)\n",
    "        \n",
    "      output_adv = model(perturbed_data)\n",
    "      final_pred = output_adv.max(1, keepdim=True)[1]\n",
    "      \n",
    "      if final_pred.item == label.item:\n",
    "          correct += 1\n",
    "          if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "              adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "              adv_examples.append( (init_pred.item, final_pred.item, adv_ex) )\n",
    "      else:\n",
    "          if len(adv_examples) < 5:\n",
    "              adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "              adv_examples.append( (init_pred.item, final_pred.item, adv_ex) )\n",
    "\n",
    "  final_acc = correct/float(len(test_loader))\n",
    "  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "  return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e4a6e",
   "metadata": {},
   "source": [
    "### We are also able to plot the accuracy as a curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b47af98",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m examples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eps \u001b[38;5;129;01min\u001b[39;00m epsilons:\n\u001b[0;32m----> 8\u001b[0m     acc, ex \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattack\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     accuracies\u001b[38;5;241m.\u001b[39mappend(acc)\n\u001b[1;32m     10\u001b[0m     examples\u001b[38;5;241m.\u001b[39mappend(ex)\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, epsilon, attack)\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, label \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m----> 8\u001b[0m     img, label \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m     img\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(img)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/cuda/__init__.py:149\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use CUDA with multiprocessing, you must use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg)\n\u001b[0;32m--> 149\u001b[0m \u001b[43m_check_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ITS5200/lib/python3.8/site-packages/torch/cuda/__init__.py:47\u001b[0m, in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_driver\u001b[39m():\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_isDriverSufficient\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_isDriverSufficient():\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDriverVersion() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;66;03m# found no NVIDIA driver on the system\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "epsilons = [0,0.007,0.01,0.02,0.03,0.05,0.1,0.2,0.3]\n",
    "\n",
    "for attack in (\"fgsm\",\"ifgsm\",\"mifgsm\"):\n",
    "  accuracies = []\n",
    "  examples = []\n",
    "\n",
    "  for eps in epsilons:\n",
    "      acc, ex = test(model, 'cuda',train_loader,eps,attack)\n",
    "      accuracies.append(acc)\n",
    "      examples.append(ex)\n",
    "\n",
    "  plt.figure(figsize=(5,5))\n",
    "  plt.plot(epsilons, accuracies, \"*-\")\n",
    "  plt.title(attack)\n",
    "  plt.xlabel(\"Epsilon\")\n",
    "  plt.ylabel(\"Accuracy\")\n",
    "  plt.show()\n",
    "\n",
    "  cnt = 0\n",
    "  plt.figure(figsize=(8,10))\n",
    "\n",
    "  for i in range(len(epsilons)):\n",
    "      for j in range(len(examples[i])):\n",
    "\n",
    "          cnt += 1\n",
    "          plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "          plt.xticks([], [])\n",
    "          plt.yticks([], [])\n",
    "\n",
    "          if j == 0:\n",
    "              plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "          orig,adv,ex = examples[i][j]\n",
    "          plt.title(\"{} -> {}\".format(orig, adv))\n",
    "          plt.imshow(ex, cmap=\"gray\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f623e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITS5200",
   "language": "python",
   "name": "its5200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
